# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Ответ
Я предлагаю использовать облачный Gitlab и подключить к нему собственные сервера с раннерами (агентами сборки). Для хранения секретных данных я предлагаю использовать Hashicorp Vault. Gitlab является универсальной системой, которая перекрывает большинство потребностей нашей задачи, для хранения паролей мы подключаем стороннюю систему.


- облачная система - множество облачных провайдеров предоставляет услуги Managed GitLab;
- система контроля версий Git - Gitlab предоставляет свой GIT cервер, в котором можно заводить проекты (git-репозитории);
- репозиторий на каждый сервис - в GitLab это называется проекты;
- запуск сборки по событию из системы контроля версий - gitlab позволяет настроить запуск сборки по событию, например по пушу или мерджу;
- запуск сборки по кнопке с указанием параметров - в гитлабе есть кнопка Run Pipeline (Run Job), после нажатия которой можно указать необходимые параметры и их значения;
- возможность привязать настройки к каждой сборке - Gitlab позволяет задавать глобальные настройки и отдельные настройки под каждый проект, они имеют приоритет выше глобальных;
- возможность создания шаблонов для различных конфигураций сборок Gitlab предлагает несколько шаблонов при создании нового проекта, также мы можем добавить свои;
- возможность безопасного хранения секретных данных (пароли, ключи доступа) - пароли и ключи будем хранить в Hashicorp Vault;
- несколько конфигураций для сборки из одного репозитория - мы можем указать переменные для сборки и использовать их в зависимости от условий сборки;
- кастомные шаги при сборке - GitLab позволяет прописать стейджи для каждой сборки с условиями их выполнения;
- собственные докер-образы для сборки проектов - в Gitlab есть собственный docker registry, в который можно загружать образы;
- возможность развернуть агентов сборки на собственных серверах - gitlab позволяет подключать собственные сервера с раннерами к облачному решению;
- возможность параллельного запуска нескольких сборок - gitlab позволяет указать , сколько сборок может идти параллельно;
- возможность параллельного запуска тестов - gitlab позволяет запустить несколько test стейджев параллельно.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Ответ
Я предлагаю исользовать ELK стэк - базу данных Elasticsearch, сервер обработки логов logstash и веб-интерфейс для работы с логами kibana. В качестве агентов для сбора логов на серверах мы будем использовать filebeat. Filebeat будет отправлять логи в очередь в kafka, на которую будет подписан logstash. Стек ELK хорошо работает с filebeat, а kafka принимает любой тип сообщений.

- сбор логов в центральное хранилище со всех хостов, обслуживающих систему - для этого подойдёт сервис logstash, который будет принимать логи со всех систем, обрабатывать их по заданным правилам и отправлять в elasticsearch;
- минимальные требования к приложениям, сбор логов из stdout - для этого мы должны использовать filebeat;
- гарантированная доставка логов до центрального хранилища - за это будет отвечать брокер сообщений kafka;
- обеспечение поиска и фильтрации по записям логов - для этого будет использоваться интерфейс kibana при помощи запросов к elasticsearch;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов - для этого будет использоваться интерфейс kibana;
- возможность дать ссылку на сохранённый поиск по записям логов - за это будет отвечать kibana.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Ответ

Для сбора и хранения метрик я предлагаю использовать Prometheus, для экспорта метрик различные экспортеры (Node exporter, Postgres exporter, MongoDB exporter, ...), для визуализации Grafana, для алертинга alertmanager. Я выбираю эту связку сервисов, как проверенную в такой конфигурации.

- сбор метрик со всех хостов, обслуживающих систему - за это будет отвечать prometheus;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network - метрики будут собирать экспортеры (Node exporter);
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network - метрики будут собирать экспортеры (Node exporter);
- сбор метрик, специфичных для каждого сервиса - метрики будут собирать экспортеры (Postgres exporter, MongoDB exporter);
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию - за это отвечает веб-интерфейс prometheus;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы - за это отвечает Grafana.


## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
